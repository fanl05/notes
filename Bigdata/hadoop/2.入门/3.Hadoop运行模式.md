# Hadoop 运行模式
- 本地模式： 单机运行，只是用来演示一下官方案例。生产环境不用。
- 伪分布式模式：也是单机运行，但是具备 Hadoop 集群的所有功能，一台服务器模拟一个分布式的环境。个别缺钱的公司用来测试，生产环境不用。
- 完全分布式模式：多台服务器组成分布式环境。生产环境使用。
## 本地运行模式（官方 WordCount）
1. 在 hadoop-3.1.3 文件下面创建一个 wcinput 文件夹
2. 在 wcinput 文件下创建一个 word.txt 文件
3. 编辑 word.txt 文件
    ```
    hadoop flink
    spark
    vip hive
    vip
    ```
4. 执行程序
   ```cmd
   hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount wcinput wcoutput
   ```
5. 查看结果
   ```cmd
   cat wcoutput/part-r-00000
   ```
   结果如下
   ```
   flink 1
   hadoop 1
   hive 1
   spark 1
   vip 2
   ```
## 完全分布式运行模式
步骤：
1. 准备 3 台客户机（关闭防火墙、静态 IP、主机名称）
2. 安装 JDK
3. 配置环境变量
4. 安装 Hadoop
5. 配置环境变量
6. 配置集群
7. 单点启动
8. 配置 ssh
9. 群起并测试集群
### 虚拟机准备
见 Hadoop运行环境搭建.md
### 编写集群分发脚本 xsync
1. scp(secure copy)安全拷贝
   1. scp 可以实现服务器与服务器之间的数据拷贝
   2. 基本语法
        ```cmd
        scp -r $pdir/$fname $user@$host:$pdir/$fname
        ```
        - -r: 递归
        - $pdir: 要拷贝的文件路径
        - $fname: 要拷贝的文件名称
        - $user: 目的地用户
        - $host: 主机
        - $pdir: 目的地文件路径
        - $fname: 目的地文件名称
    3. 实操
       1. 在 hadoop102、hadoop103、hadoop104 都已经创建好的/opt/module, /opt/software 两个目录，并且已经把这两个目录修改为 ryland:ryland
       2. 在 hadoop102 上，将 hadoop102 中/opt/module/jdk1.8.0_212 目录拷贝到 hadoop103 上 `scp -r /opt/module/jdk1.8.0_212 ryland@hadoop103:/opt/module`
       3. 在 hadoop103 上，将 hadoop102 中/opt/module/hadoop-3.1.3 目录拷贝到 hadoop103 上 `scp -r ryland@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/`
       4. 在 hadoop103 上操作，将 hadoop102 中/opt/module 目录下所有目录拷贝到 hadoop104 上 `scp -r ryland@hadoop102:/opt/module/* ryland@hadoop104:/opt/module`
2. rsync 远程同步工具
rsync 主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点

rsync 和 scp 区别：用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更新；scp 是把所有文件都复制过去

基本语法 `rsync -av $pdir/$fname $user@$host:$pdir/$fname`
选项参数说明 -a: 归档拷贝 -v: 显示复制过程

实操，同步 hadoop102 中的/opt/module/hadoop-3.1.3 到 hadoop103 `rsync -av hadoop-3.1.3/ ryland@hadoop103:/opt/module/hadoop-3.1.3/`

3. xsync 集群分发脚本

在/home/ryland/bin 目录下创建 xsync 文件
```bash
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
 echo Not Enough Arguement!
 exit;
fi
#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
 echo ==================== $host ====================
 #3. 遍历所有目录，挨个发送
 for file in $@
 do
 #4. 判断文件是否存在
  if [ -e $file ]
   then
    #5. 获取父目录
    pdir=$(cd -P $(dirname $file); pwd)
    #6. 获取当前文件的名称
    fname=$(basename $file)
    ssh $host "mkdir -p $pdir"
    rsync -av $pdir/$fname $host:$pdir
   else
    echo $file does not exists!
  fi
 done
done
```

修改执行权限 `chmod +x xsync`

测试脚本 `xsync /home/ryland/bin`

将脚本复制到 /bin，全局使用 `sudo cp xsync /bin/`

同步环境变量配置（root 所有者），如果用了 sudo，那么 xsync 一定要给它的路径补全 `sudo ./bin/xsync /etc/profile.d/my_env.sh`

让环境变量生效 `source /etc/profile`


### SSH 无密登录配置
### 集群配置
### 启动集群
### 配置历史服务器
